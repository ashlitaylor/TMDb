{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ashlitaylor/ashlitaylor.github.io/master/images/Popcorn.jpeg\" height=\"600\" width=\"400\">\n",
    "<header> \n",
    "    <h2 align=\"center\"> Scraping, Cleaning, and Graphing The Movie Database \"Drama\" data </h2>\n",
    "    <h6 align=\"center\"> Python code to run API </h6>\n",
    "</header>\n",
    "\n",
    "The Movie Database [TMDb](https://www.themoviedb.org/) is a popular, user editable database for movies and TV shows. This Python code accesses the API to scrape and parse data for 350 movies that have been released in the 'Drama' genre since 2004 and five movies that are similar with the goal of graphing a network of Drama movies that are similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before Running the code\n",
    "An API key is needed to access the TMDb data and run the code.\n",
    "* How to get a [TMDb account](https://www.themoviedb.org/account/signup)\n",
    "* Request an [API key](https://docs.google.com/document/d/e/2PACX-1vQkWjHiLS1Xu2HZNQ7Egv08l_DdPnugoxUOZ0ugqBNHWY529xWB417QoSS0MbIih6PS9gu1Y1D-NFDT/pub)\n",
    "* TMDb API [Documentation](https://developers.themoviedb.org/3/getting-started/introduction)\n",
    "\n",
    "I removed all duplicate movie pairs. That is, if both the pairs A,B and B,A are present, I only keep A,B where the value of title A is less than thevalue of title B. After removing duplicate pairs, I request five similar movies and output the data to a CSV file. I used the data from the CSV file to generate a graph using Gephi that maps movie similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the necessary modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "#import time\n",
    "import sys\n",
    "#import collections\n",
    "import urllib\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import threading\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Drama Query\n",
    "The code cell below takes the user's unique API key as the input for when the query is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first created an empty dictionary to store the raw query data, and an empty list to store the list of pages of the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drama_genre_query = {}\n",
    "drama_list_pages = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the API to search for movies in the ‘Drama’ genre released in the year 2004 or later. I retrieve the 350 most popular movies in this genre and sort them from most popular to least popular. Multiple API calls are needed to retrieve all movies. Each query returns one page that contains 20 data instances, so I use a 'for' loop to request the first 18 pages that contains data for the top 18 x 20 = 360 movie titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1b_url = 'https://api.themoviedb.org/3/discover/movie?api_key=' + API_KEY + '&language=en-US&sort_by=popularity.desc&include_adult=false&include_video=false&primary_release_date.gte=2004-01-01&with_genres=18'\n",
    "pages = list(range(1,19))\n",
    "for i in pages:\n",
    "    page_url_append = '&page=' + str(i)\n",
    "    drama_page = json.load(urllib.request.urlopen(q1b_url+page_url_append))\n",
    "    drama_results = drama_page['results']\n",
    "    drama_list_pages.append(drama_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a dictionary containing movie-ID and title key:value pairs with top 350 movies and saved the data to a csv file. Each line in the file describes one movie, in the following format: movie-ID,movie-name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(0, (len(drama_list_pages))):\n",
    "    for movie in range(0, (len(drama_list_pages[page]))):\n",
    "        movie_id = drama_list_pages[page][movie]['id']\n",
    "        movie_name = drama_list_pages[page][movie]['title']\n",
    "        if len(drama_genre_query) < 350:\n",
    "            drama_genre_query.update({movie_id: movie_name})\n",
    "#Writing movies to CSV file\n",
    "csv_file = 'movie_ID_name.csv'\n",
    "with open(csv_file, 'w', encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)    \n",
    "    writer.writerows(drama_genre_query.items()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Similar movie retrieval\n",
    "For each movie I retrieved, I used the API to find its 5 similar movies. The API will return as many as it can find, so I made my code code flexible to work with however many movies the API returned. I looped through each movie title that I collected with my first API call to use a function to obtain the similar movies. The API allows 40 requests every 10 seconds, so I built a timeout interval into my code while looping through the requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlfront = 'https://api.themoviedb.org/3/movie/'\n",
    "urlend = '/similar?api_key=' + API_KEY + '&language=en-US&page=1'\n",
    "similar_movie_list = list()\n",
    "\n",
    "def similarrequest(queryurl):\n",
    "    similar_movie_query = json.load(urllib.request.urlopen(queryurl))\n",
    "    similar_movies = similar_movie_query['results']\n",
    "    if len(similar_movies) > 5:\n",
    "        similar_movies = similar_movies[0:5]\n",
    "    for target in range(0, len(similar_movies)):\n",
    "        target_movie_id = similar_movies[target]['id']\n",
    "        similar_pair = source, target_movie_id\n",
    "        similar_movie_list.append(similar_pair)    \n",
    "\n",
    "for source in drama_genre_query:\n",
    "    queryurl = urlfront + str(source) + urlend\n",
    "    requesttimer = threading.Timer(0.25, similarrequest(queryurl))\n",
    "    requesttimer.start()    \n",
    "    requesttimer.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Deduplication\n",
    "After I found all similar movies, I removed all duplicate movie pairs. That is, if both the pairs A,B and B,A are present, I only keep A,B where A < B. I saved the results in a csv file, where each line in the file describes one pair of similar movies in format movie-ID,similar-movie-ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paircount = defaultdict(int)\n",
    "test_list = similar_movie_list.copy()\n",
    "for source, target in test_list:\n",
    "    pair = (min(source, target), max(source, target))\n",
    "    paircount[pair] += 1\n",
    "    #print(list(paircount.keys()))\n",
    "paircount = defaultdict(int)\n",
    "update_list = similar_movie_list.copy()\n",
    "for source, target in update_list:\n",
    "    pair = (min(source, target), max(source, target))\n",
    "    paircount[pair] += 1\n",
    "for source, target in paircount:\n",
    "    pair = source, target\n",
    "    if(paircount[pair]) >= 2:\n",
    "        pair_remove = target, source\n",
    "        update_list.remove(pair_remove)\n",
    "similar_dict = dict(update_list)\n",
    "\n",
    "#Writing to CSV file\n",
    "csv_file = 'movie_ID_sim_movie.csv'\n",
    "with open(csv_file, 'w', encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(similar_dict.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Similar movie network graph\n",
    "\n",
    "After I pulled the movie-ID:similar-movie-ID pairs, I used [Gephi](https://gephi.org/) to create the graph below that maps the movie similarity. I chose to color and scale the nodes based on the number of in-degree connections\n",
    "\n",
    "<img src=\"https://ashlitaylor.github.io/TMDb/graph.png\" height=\"600\" width=\"400\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
